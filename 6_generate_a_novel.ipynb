{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdtZwiNTTf8LZ5QkNYyNa9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtajeong/ChatGPT_for_Management/blob/main/6_generate_a_novel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating a novel\n",
        "- using Pre-trained model 'gpt2'"
      ],
      "metadata": {
        "id": "_t5mRSiL1jpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# 시작 프롬프트 정의\n",
        "prompt = \"Once upon a time\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Auto-regressive 방식으로 텍스트 생성\n",
        "output_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=100,  # 생성될 최대 토큰 수\n",
        "    num_return_sequences=1,  # 한 번의 실행에서 몇 개의 문장을 생성할지를 지정\n",
        "    temperature=0.7,  # 샘플링 다양성 조절\n",
        "    top_k=50,  # 높은 확률의 상위 50개 토큰만 고려\n",
        "    repetition_penalty=1.2,\n",
        ")\n",
        "\n",
        "# 결과 출력\n",
        "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr98IszU1pDF",
        "outputId": "b1ccb5b7-d5aa-422a-8cd8-332cbb384db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was filled with people who were not only rich but also powerful.\n",
            "The first thing that came to mind when I thought of this is how much money they had in their pockets and what kind it would be if someone took them out on an adventure or something like those things? The amount you could spend at any given moment without having anyone else's attention! It seemed so simple for me… But then again maybe there are some more interesting ways around these kinds \"money\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "7LclL-zS4zZN",
        "outputId": "32e45a6f-1d45-4d9b-a671-2ea44c97f7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Once upon a time, the world was filled with people who were not only rich but also powerful.\\nThe first thing that came to mind when I thought of this is how much money they had in their pockets and what kind it would be if someone took them out on an adventure or something like those things? The amount you could spend at any given moment without having anyone else\\'s attention! It seemed so simple for me… But then again maybe there are some more interesting ways around these kinds \"money'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Generating (모델 훈련과 생성 과정)\n",
        "- using LSTM model"
      ],
      "metadata": {
        "id": "xFeY5f5xC3wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 텍스트 데이터 준비\n",
        "\n",
        "text = \"\"\"\n",
        "Once upon a time, there was a little prince who lived on a small planet.\n",
        "He loved watching sunsets and exploring the stars. One day, he decided to visit other planets...\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Mtpz9D-aEGLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Once upon a time, there was a little prince who lived on a tiny planet no larger than a house.\n",
        "The planet had three volcanoes, two active and one extinct. The prince carefully tended to them,\n",
        "removing weeds and cleaning the craters to prevent any eruptions.\n",
        "\n",
        "The little prince loved watching sunsets. On his small planet, he could see the sunset simply by moving his chair a few steps.\n",
        "One day, he watched the sunset forty-four times because he was feeling particularly sad.\n",
        "\n",
        "The little prince also took care of a rose, a beautiful but proud flower that had appeared on his planet.\n",
        "The rose often demanded attention and made the prince question her love for him. But deep down, he loved her dearly.\n",
        "\n",
        "Feeling confused and lonely, the little prince decided to leave his planet and explore the universe.\n",
        "He visited many planets, each inhabited by strange and interesting characters.\n",
        "\n",
        "On one planet, he met a king who claimed to rule the stars. The king believed his orders were absolute, but the prince found him amusing.\n",
        "On another planet, he encountered a businessman who spent his days counting stars, believing they were his property.\n",
        "The prince also met a lamplighter who lit and extinguished a streetlamp every minute due to the fast rotation of his tiny planet.\n",
        "\n",
        "Through these encounters, the little prince learned about grown-ups and their odd priorities.\n",
        "Eventually, he arrived on Earth, where he met a fox. The fox taught the prince about relationships,\n",
        "explaining that love and friendship require time, patience, and responsibility.\n",
        "\n",
        "The fox said, \"What is essential is invisible to the eye.\" The little prince never forgot these words.\n",
        "After meeting the fox, the prince began to see the world differently. He realized the importance of the rose he had left behind\n",
        "and decided to return to his planet to care for her once more.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "-rSVjFnnQfqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 텍스트 전처리: 텍스트 데이터를 LSTM 모델이 이해할 수 있는 숫자(정수 인덱스)로 변환\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 토큰화 및 정수 인덱싱\n",
        "tokenizer = Tokenizer(char_level=True, lower=False)  # char 단위로 처리\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_chars = len(tokenizer.word_index)\n",
        "\n",
        "# 시퀀스 생성\n",
        "sequence_length = 40\n",
        "sequences = []\n",
        "for i in range(len(text) - sequence_length):\n",
        "    seq = text[i:i + sequence_length]\n",
        "    next_char = text[i + sequence_length]\n",
        "    sequences.append((seq, next_char))\n",
        "\n",
        "# 입력(x)과 출력(y)으로 나누기\n",
        "x = []\n",
        "y = []\n",
        "for seq, next_char in sequences:\n",
        "    x.append(tokenizer.texts_to_sequences([seq])[0])\n",
        "    y.append(tokenizer.word_index[next_char])\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# One-hot encoding 출력\n",
        "y = to_categorical(y, num_classes=total_chars + 1)\n"
      ],
      "metadata": {
        "id": "PYG7isQ7EfRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXZkdp1sJD5I",
        "outputId": "7890e5f5-8b05-4f11-8db3-d7b869813f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\\nOnce upon a time, there was a little pr', 'i'),\n",
              " ('Once upon a time, there was a little pri', 'n'),\n",
              " ('nce upon a time, there was a little prin', 'c'),\n",
              " ('ce upon a time, there was a little princ', 'e'),\n",
              " ('e upon a time, there was a little prince', ' '),\n",
              " (' upon a time, there was a little prince ', 'w'),\n",
              " ('upon a time, there was a little prince w', 'h')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(x[i], y[i]) for i in range(7)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1wilCVlFiQe",
        "outputId": "5fe07ee8-530c-4d1a-82f2-a8ecb787c080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([17, 28,  4, 14,  2,  1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2,\n",
              "         21,  1,  3,  8,  2,  7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,\n",
              "          3, 11,  2,  1, 13,  7]),\n",
              "  array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([28,  4, 14,  2,  1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,\n",
              "          1,  3,  8,  2,  7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3,\n",
              "         11,  2,  1, 13,  7,  6]),\n",
              "  array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([ 4, 14,  2,  1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,  1,\n",
              "          3,  8,  2,  7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3, 11,\n",
              "          2,  1, 13,  7,  6,  4]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([14,  2,  1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,  1,  3,\n",
              "          8,  2,  7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3, 11,  2,\n",
              "          1, 13,  7,  6,  4, 14]),\n",
              "  array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([ 2,  1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,  1,  3,  8,\n",
              "          2,  7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3, 11,  2,  1,\n",
              "         13,  7,  6,  4, 14,  2]),\n",
              "  array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([ 1, 15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,  1,  3,  8,  2,\n",
              "          7,  2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3, 11,  2,  1, 13,\n",
              "          7,  6,  4, 14,  2,  1]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.])),\n",
              " (array([15, 13,  9,  4,  1,  5,  1,  3,  6, 18,  2, 21,  1,  3,  8,  2,  7,\n",
              "          2,  1, 24,  5, 10,  1,  5,  1, 11,  6,  3,  3, 11,  2,  1, 13,  7,\n",
              "          6,  4, 14,  2,  1, 24]),\n",
              "  array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0.]))]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. LSTM 모델 생성: 텍스트 시퀀스를 입력으로 받아 다음 문자(토큰)를 예측하는 LSTM 모델을 정의\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input\n",
        "\n",
        "# 모델 정의\n",
        "model = Sequential([\n",
        "    Input(shape=(sequence_length,)),\n",
        "    Embedding(input_dim=total_chars + 1, output_dim=20),\n",
        "    LSTM(150, return_sequences=False, dropout=0.2),\n",
        "    Dense(total_chars + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# model.build((None, sequence_length))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "L-3gaa_iFnS2",
        "outputId": "b0aa3113-0ec5-41de-9e55-415b3ed5f7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m20\u001b[0m)              │             \u001b[38;5;34m800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m102,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │           \u001b[38;5;34m6,040\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,040</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,440\u001b[0m (427.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,440</span> (427.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,440\u001b[0m (427.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,440</span> (427.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 훈련: 모델을 훈련하여 텍스트 패턴을 학습\n",
        "\n",
        "model.fit(x, y, epochs=100, batch_size=64, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lojtzvjQGkCH",
        "outputId": "9c8998e4-3a8d-4f8d-ef4c-3942925d2a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784d4dbb8610>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_text(model, tokenizer, seed_text, num_generate=100):\n",
        "    sequence_length = 40  # 모델 입력 크기\n",
        "    result = seed_text\n",
        "\n",
        "    for i in range(num_generate):\n",
        "        # 입력 시퀀스를 모델 크기에 맞게 자르기\n",
        "        input_text = result[-sequence_length:]\n",
        "\n",
        "        # 시퀀스를 인덱스로 변환\n",
        "        input_seq = [tokenizer.word_index[char] for char in input_text if char in tokenizer.word_index]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=sequence_length, padding='pre')\n",
        "\n",
        "        # 모델 예측\n",
        "\n",
        "        predicted_probs = model.predict(input_seq, verbose=0)\n",
        "        predicted_char_idx = np.argmax(predicted_probs)\n",
        "\n",
        "        # 인덱스를 문자로 변환\n",
        "        if predicted_char_idx in tokenizer.index_word:\n",
        "            predicted_char = tokenizer.index_word[predicted_char_idx]\n",
        "        else:\n",
        "            # print(f\"Warning: Index {predicted_char_idx} not in tokenizer.index_word\")\n",
        "            break\n",
        "\n",
        "        # 결과에 추가\n",
        "        result += predicted_char\n",
        "        # print(result)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "rhbY_j2rPBm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성\n",
        "seed = \"Once upon a time, there was a \"\n",
        "generated_text = generate_text(model, tokenizer, seed_text=seed, num_generate=200)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWCZUMKFPGio",
        "outputId": "94a2fa28-1fca-44b8-e1ec-4db0576f381a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a lemering tha cat a his pppop. the prince buster torethers, \n",
            "eFlivinitid tany pante etere the since qute he mer famd onthinclaps and theirind there ver arded on erern,, he lealined to rele to the fort.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------"
      ],
      "metadata": {
        "id": "lfXMKaFsTQj4"
      }
    }
  ]
}